{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "NqEKQNV5Y4pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries if needed (this step is often unnecessary in Colab)\n",
        "!pip install numpy pandas matplotlib\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional: Print versions to verify installations\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni6b1BZyUJyy",
        "outputId": "80fddfdd-9fa2-408c-f2ed-13363e509e03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "NumPy version: 1.26.4\n",
            "Pandas version: 2.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea6Cy6ruTpTm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/ClupusVT/AI_machine_learning/97a67fa8cd900213b0b5b35bb82cba9855dd3613/1st_Self_learning/data_house_price.csv').values\n",
        "N = data.shape[0]\n",
        "x = data[:, 0].reshape(-1, 1)\n",
        "y = data[:, 1].reshape(-1, 1)\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel('mét vuông')\n",
        "plt.ylabel('giá')\n",
        "\n",
        "x = np.hstack((np.ones((N, 1)), x))\n",
        "\n",
        "w = np.array([0.,1.]).reshape(-1,1)\n",
        "\n",
        "numOfIteration = 1000\n",
        "cost = np.zeros((numOfIteration,1))\n",
        "learning_rate = 0.00001\n",
        "for i in range(1, numOfIteration):\n",
        "    r = np.dot(x, w) - y\n",
        "    cost[i] = 0.5*np.sum(r*r)\n",
        "    w[0] -= learning_rate*np.sum(r)\n",
        "    # correct the shape dimension\n",
        "    w[1] -= learning_rate*np.sum(np.multiply(r, x[:,1].reshape(-1,1)))\n",
        "    print(cost[i])\n",
        "predict = np.dot(x, w)\n",
        "plt.plot((x[0][1], x[N-1][1]),(predict[0], predict[N-1]), 'r')\n",
        "plt.show()\n",
        "\n",
        "x1 = 50\n",
        "y1 = w[0] + w[1] * 50\n",
        "print('Giá nhà cho 50m^2 là : ', y1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/ClupusVT/AI_machine_learning/97a67fa8cd900213b0b5b35bb82cba9855dd3613/1st_Self_learning/data_house_price.csv').values\n",
        "N = data.shape[0]\n",
        "x = data[:, 0].reshape(-1, 1)\n",
        "y = data[:, 1].reshape(-1, 1)\n",
        "\n",
        "# Plot data\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel('mét vuông')\n",
        "plt.ylabel('giá')\n",
        "\n",
        "# Add bias term\n",
        "X = np.hstack((np.ones((N, 1)), x))\n",
        "\n",
        "# Initialize weights\n",
        "w = np.zeros((2, 1))\n",
        "\n",
        "# Set hyperparameters\n",
        "num_iterations = 1000\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Gradient Descent\n",
        "for _ in range(num_iterations):\n",
        "    predictions = X @ w\n",
        "    errors = predictions - y\n",
        "    gradients = (X.T @ errors) / N\n",
        "    w -= learning_rate * gradients\n",
        "\n",
        "    # Optional: Calculate and print cost\n",
        "    cost = (errors ** 2).sum() / (2 * N)\n",
        "    print(f'Cost: {cost}')\n",
        "\n",
        "# Plot the regression line\n",
        "plt.plot(x, X @ w, 'r')\n",
        "plt.show()\n",
        "\n",
        "# Prediction\n",
        "x1 = 50\n",
        "y1 = w[0] + w[1] * x1\n",
        "print(f'Giá nhà cho {x1}m^2 là : {y1[0]}')\n"
      ],
      "metadata": {
        "id": "_bAwJrJzXv_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **How the code optimize the linear regression** **bold text**\n",
        "1. Matrix Multiplication (X @ w and X.T @ errors):\n",
        "X @ w: This performs a matrix multiplication between the feature matrix X and the weight vector w. In linear algebra, this computes the predicted values for all training examples in one operation. Matrix multiplication is optimized in NumPy and allows for parallel computation, making it much faster than iterating through each data point.\n",
        "X.T @ errors: This computes the gradient of the cost function with respect to the weights in one operation. By taking the dot product of the transpose of X and the errors, it efficiently calculates the gradients without needing explicit loops.\n",
        "2. Avoiding Explicit Loops:\n",
        "The code avoids explicit loops for updating each weight individually. Instead, it uses vectorized operations which are inherently faster due to optimized low-level implementations in NumPy. These operations are highly optimized for performance and make use of efficient memory access patterns and parallel processing.\n",
        "3. Gradient Calculation:\n",
        "gradients = (X.T @ errors) / N: This computes the gradient of the cost function with respect to the weights. By dividing by N, it averages the gradient over all data points. This approach ensures that the gradient calculation is vectorized and leverages the efficiency of matrix operations.\n",
        "4. Weight Update:\n",
        "w -= learning_rate * gradients: This performs a single operation to update all weights simultaneously. The vectorized approach ensures that weight updates are done efficiently, avoiding the overhead of multiple individual updates.\n",
        "5. Cost Calculation:\n",
        "cost = (errors ** 2).sum() / (2 * N): Calculates the cost in a vectorized manner. This ensures that the cost function is computed quickly by summing the squared errors over all data points in one operation.\n",
        "Summary of Benefits:\n",
        "Speed: Matrix operations are highly optimized for performance. NumPy's underlying implementation leverages low-level optimizations, multi-threading, and vectorization to perform operations faster than loops.\n",
        "Simplicity: Vectorized operations make the code cleaner and easier to understand. It avoids the need for nested loops and manual index management.\n",
        "Scalability: Matrix operations scale better with larger datasets and higher-dimensional feature spaces, making them more suitable for real-world applications."
      ],
      "metadata": {
        "id": "NXRx4ZQ3YTkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n"
      ],
      "metadata": {
        "id": "BalwjLHtgEFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Feb 26 13:49:07 2019\n",
        "\n",
        "@author: DELL\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hàm sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Load data từ file csv\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/nttuan8/DL_Tutorial/master/L2/dataset.csv').values\n",
        "N, d = data.shape\n",
        "x = data[:, 0:d-1].reshape(-1, d-1)\n",
        "y = data[:, 2].reshape(-1, 1)\n",
        "\n",
        "# Vẽ data bằng scatter\n",
        "x_cho_vay = x[y[:,0]==1]\n",
        "x_tu_choi = x[y[:,0]==0]\n",
        "\n",
        "plt.scatter(x_cho_vay[:, 0], x_cho_vay[:, 1], c='red', edgecolors='none', s=30, label='cho vay')\n",
        "plt.scatter(x_tu_choi[:, 0], x_tu_choi[:, 1], c='blue', edgecolors='none', s=30, label='từ chối')\n",
        "plt.legend(loc=1)\n",
        "plt.xlabel('mức lương (triệu)')\n",
        "plt.ylabel('kinh nghiệm (năm)')\n",
        "\n",
        "# Thêm cột 1 vào dữ liệu x\n",
        "x = np.hstack((np.ones((N, 1)), x))\n",
        "\n",
        "w = np.array([0.,0.1,0.1]).reshape(-1,1)\n",
        "\n",
        "# Số lần lặp bước 2\n",
        "numOfIteration = 1000\n",
        "cost = np.zeros((numOfIteration,1))\n",
        "learning_rate = 0.01\n",
        "\n",
        "for i in range(1, numOfIteration):\n",
        "\n",
        "\t # Tính giá trị dự đoán\n",
        "    y_predict = sigmoid(np.dot(x, w))\n",
        "    cost[i] = -np.sum(np.multiply(y, np.log(y_predict)) + np.multiply(1-y, np.log(1-y_predict)))\n",
        "    # Gradient descent\n",
        "    w = w - learning_rate * np.dot(x.T, y_predict-y)\n",
        "    print(cost[i])\n",
        "\n",
        "# Vẽ đường phân cách.\n",
        "t = 0.5\n",
        "plt.plot((4, 10),(-(w[0]+4*w[1]+ np.log(1/t-1))/w[2], -(w[0] + 10*w[1]+ np.log(1/t-1))/w[2]), 'g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lyjuikWsffZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "y1crTVu5qPDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical  # Updated import\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)  # Updated function\n",
        "y_test = to_categorical(y_test, 10)    # Updated function\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi3Liro4pEz1",
        "outputId": "085f7aaf-afe3-4bd0-8d78-b6a6f50d468f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - accuracy: 0.8306 - loss: 0.5500 - val_accuracy: 0.9723 - val_loss: 0.0885\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 63ms/step - accuracy: 0.9643 - loss: 0.1226 - val_accuracy: 0.9786 - val_loss: 0.0672\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step - accuracy: 0.9734 - loss: 0.0887 - val_accuracy: 0.9827 - val_loss: 0.0507\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 70ms/step - accuracy: 0.9772 - loss: 0.0738 - val_accuracy: 0.9843 - val_loss: 0.0448\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - accuracy: 0.9819 - loss: 0.0597 - val_accuracy: 0.9843 - val_loss: 0.0456\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 72ms/step - accuracy: 0.9834 - loss: 0.0540 - val_accuracy: 0.9851 - val_loss: 0.0417\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 69ms/step - accuracy: 0.9859 - loss: 0.0441 - val_accuracy: 0.9865 - val_loss: 0.0406\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 65ms/step - accuracy: 0.9871 - loss: 0.0409 - val_accuracy: 0.9887 - val_loss: 0.0376\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.9872 - loss: 0.0378 - val_accuracy: 0.9866 - val_loss: 0.0383\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 68ms/step - accuracy: 0.9888 - loss: 0.0358 - val_accuracy: 0.9867 - val_loss: 0.0418\n",
            "Test loss: 0.04176126793026924\n",
            "Test accuracy: 0.9866999983787537\n"
          ]
        }
      ]
    }
  ]
}