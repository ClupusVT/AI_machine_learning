{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yj3SBhSCVVr"
      },
      "source": [
        "- Download dataset from kaggle (kaggle dataset)\n",
        "- Download the validate image set\n",
        "- Show some images\n",
        "- Use the default Yolov8 model to detect object in kaggle dataset\n",
        "- Train 1st model\n",
        "- Use 1st model to detect object in kaggle dataset -> good\n",
        "- Use 1st model to detect object validate image set -> bad\n",
        "- Use team model to detect object validate image set -> neutral , have a better result\n",
        "-> The 1st model have been overfitted\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNG3jZmefj9n",
        "outputId": "c6aa54c2-863f-48f8-9130-2ef0275b22f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/80.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unzip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q roboflow\n",
        "!pip install -q unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U30wSh4ufo6C",
        "outputId": "44a60108-8db1-4198-c14b-8e3339ddccc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 41527, done.\u001b[K\n",
            "remote: Counting objects: 100% (265/265), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 41527 (delta 132), reused 163 (delta 55), pack-reused 41262 (from 1)\u001b[K\n",
            "Receiving objects: 100% (41527/41527), 31.30 MiB | 20.85 MiB/s, done.\n",
            "Resolving deltas: 100% (30767/30767), done.\n",
            "/content/ultralytics\n",
            "Obtaining file:///content/ultralytics\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.95) (2.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.95) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.95) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.95) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.95) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.95) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.95) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.2.95) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.2.95) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.2.95) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.2.95) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.2.95) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.2.95) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.2.95) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.95) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.95) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.95) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.95) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.95) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.95) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.2.95) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.2.95) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics==8.2.95) (1.3.0)\n",
            "Building wheels for collected packages: ultralytics\n",
            "  Building editable for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ultralytics: filename=ultralytics-8.2.95-0.editable-py3-none-any.whl size=23033 sha256=4cbe674d88a5bb7f188f1fb02f086677c0de0456625991c969df89f87ad60108\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vmommd9l/wheels/9a/cd/d5/95912172899f8ec640166ff6eef49156b1b00d6b2ade4a3cb1\n",
            "Successfully built ultralytics\n",
            "Installing collected packages: ultralytics\n",
            "  Attempting uninstall: ultralytics\n",
            "    Found existing installation: ultralytics 8.2.95\n",
            "    Uninstalling ultralytics-8.2.95:\n",
            "      Successfully uninstalled ultralytics-8.2.95\n",
            "Successfully installed ultralytics-8.2.95\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "44a9ec98b27b4c0aac2bacf9f9cf3a68",
              "pip_warning": {
                "packages": [
                  "ultralytics"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/ultralytics/ultralytics.git\n",
        "%cd ultralytics\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ymxlwbG9dNzg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Video\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "import pathlib\n",
        "import glob\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b0clexF5gi92"
      },
      "outputs": [],
      "source": [
        "# Configure the visual appearance of Seaborn plots\n",
        "sns.set(rc={'axes.facecolor': '#eae8fa'}, style='darkgrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "bSRsRjPhgmzs",
        "outputId": "0a4c164e-1331-4718-9ac4-45b7a26807df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-32eca3ff-3482-4ec2-88ab-7d3983342e3c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-32eca3ff-3482-4ec2-88ab-7d3983342e3c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"mnhthinguyn\",\"key\":\"8e929ac7632d9908a476eb9c12e2d0e4\"}'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()  # This will prompt you to upload the kaggle.json file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ybNlVn1hJxz"
      },
      "outputs": [],
      "source": [
        "# Step 2: Move kaggle.json to the correct location\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Step 3: Set permissions\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# Install Kaggle package\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiZTUd2qhTFS",
        "outputId": "ab79d46f-5a4b-4917-ad41-e7e924c3dbbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mnhthinguyn/traffic-sign-50-60-70-self-trainning\n",
            "License(s): unknown\n",
            "Downloading traffic-sign-50-60-70-self-trainning.zip to /content/specific-folder\n",
            " 25% 5.00M/19.7M [00:00<00:00, 17.8MB/s]\n",
            "100% 19.7M/19.7M [00:00<00:00, 59.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/specific-folder\n",
        "!kaggle datasets download -d mnhthinguyn/traffic-sign-50-60-70-self-trainning -p /content/specific-folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNK_AunYhtg9"
      },
      "outputs": [],
      "source": [
        "!unzip /content/specific-folder/traffic-sign-50-60-70-self-trainning.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByVd3B_2i0pw"
      },
      "source": [
        "Show Some Images From TrainSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "Et9ZZMIii0OI",
        "outputId": "cc514c89-e1b9-4d3b-87c3-3dbaa18f2777"
      },
      "outputs": [],
      "source": [
        "Image_dir = '/content/dataset/Self_trainning_sign/Self_trainning/train/images/50kmh'\n",
        "\n",
        "num_samples = 9\n",
        "image_files = os.listdir(Image_dir)\n",
        "\n",
        "# Randomly select num_samples images\n",
        "rand_images = random.sample(image_files, num_samples)\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(11, 11))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    image = rand_images[i]\n",
        "    ax = axes[i // 3, i % 3]\n",
        "    ax.imshow(plt.imread(os.path.join(Image_dir, image)))\n",
        "    ax.set_title(f'Image {i+1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEKkc-5aLVqU"
      },
      "source": [
        "Evaluate the image size on the image folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUbNW_b_k_D"
      },
      "source": [
        "Download the validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AxyfXOA_ltD"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!wget http://14.225.204.171:9998/validate_data_2.zip\n",
        "!wget http://14.225.204.171:9998/best_0827.pt\n",
        "!wget http://14.225.204.171:9998/best.pt\n",
        "!unzip /content/validate_data_2.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t16JstkDC_4m"
      },
      "source": [
        "Check the validate item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "jZwi5Ct9C_O-",
        "outputId": "6adc3044-e0a3-44ec-8c1e-afa97082f638"
      },
      "outputs": [],
      "source": [
        "Image_dir = '/content/validate/images'\n",
        "\n",
        "num_samples = 9\n",
        "image_files = os.listdir(Image_dir)\n",
        "\n",
        "# Randomly select num_samples images\n",
        "rand_images = random.sample(image_files, num_samples)\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(11, 11))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    image = rand_images[i]\n",
        "    ax = axes[i // 3, i % 3]\n",
        "    ax.imshow(plt.imread(os.path.join(Image_dir, image)))\n",
        "    ax.set_title(f'Image {i+1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAhMb4E4pTdP"
      },
      "source": [
        "Summary the model result before trainning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oAUIza9qaP4X",
        "outputId": "efa6ce87-f7a7-40f1-b1b7-f39ecf6163ff"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # Use this for displaying images in Google Colab\n",
        "\n",
        "# Load the pretrained YOLOv8n model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Define the folder containing the images\n",
        "folder_path = \"/content/dataset/Self_trainning_sign/Self_trainning/train/images/50kmh\"\n",
        "\n",
        "# Initialize counters\n",
        "total_images = 0\n",
        "images_with_detections = 0\n",
        "\n",
        "# Loop through each image in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(('.png', '.jpg', '.jpeg')):  # Ensure file is an image\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "        total_images += 1\n",
        "\n",
        "        # Use the model to detect objects in the image, suppress verbose output\n",
        "        result_predict = model.predict(source=image_path, imgsz=(640), verbose=False)\n",
        "\n",
        "        # Check if there are any detections\n",
        "        if len(result_predict[0].boxes) > 0:  # Check if there are any bounding boxes\n",
        "            images_with_detections += 1\n",
        "            print(f\"Detections found in image: {filename}\")\n",
        "\n",
        "            # Display the detected image\n",
        "            detected_img = result_predict[0].plot()  # Plot the detections on the image\n",
        "            cv2_imshow(detected_img)  # Display the image in Google Colab\n",
        "\n",
        "# Calculate the percentage of images with detections\n",
        "if total_images > 0:\n",
        "    detection_percentage = (images_with_detections / total_images) * 100\n",
        "else:\n",
        "    detection_percentage = 0\n",
        "\n",
        "# Print the overall report\n",
        "print(f\"Total images processed: {total_images}\")\n",
        "print(f\"Images with detections: {images_with_detections}\")\n",
        "print(f\"Percentage of images with detections: {detection_percentage:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH70xG_yqjuT"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=train model=/content/dataset/Self_trainning_sign/Self_trainning/4th_periord_best.pt data=/content/dataset/Self_trainning_sign/Self_trainning/data1.yaml epochs=20 imgsz=640 batch=16\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from google.colab import files\n",
        "\n",
        "# Define the base path where YOLO saves the training results\n",
        "base_path = \"/content/ultralytics/runs/detect/\"\n",
        "\n",
        "# Get a list of all training folders\n",
        "train_folders = glob.glob(os.path.join(base_path, 'train*'))\n",
        "\n",
        "# Find the most recently modified training folder\n",
        "latest_train_folder = max(train_folders, key=os.path.getmtime)\n",
        "\n",
        "# Construct the path to the best model\n",
        "model_path = os.path.join(latest_train_folder, \"weights\", \"best.pt\")\n",
        "\n",
        "# Check if the model file exists and download it\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"Training completed. Model found in {latest_train_folder}. Preparing to download...\")\n",
        "    files.download(model_path)\n",
        "else:\n",
        "    print(\"Model not found. Please check the training process and paths.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHjoT99jM1B0"
      },
      "source": [
        "## Validate the model after training with the the valid dataset extract from the trained dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ef7RnPKZfyH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UmxOvw1ZgTE"
      },
      "source": [
        "# Validate the model after training with the the valid dataset extract from the trained dataset with images result suggesstion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-k5iKUguqFsN",
        "outputId": "bc08b117-fe82-48f3-da0a-f6dbc2e6fa29"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # Use this for displaying images in Google Colab\n",
        "from contextlib import redirect_stdout\n",
        "import logging\n",
        "\n",
        "# Suppress logging messages\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# Load the pretrained YOLOv8n model\n",
        "model = YOLO(\"/content/best.pt\")  # Load your custom-trained model\n",
        "\n",
        "# Define the folder containing the images\n",
        "folder_path = \"/content/dataset/Self_trainning_sign/Self_trainning/valid/images/50kmh\"\n",
        "\n",
        "# Initialize counters\n",
        "total_images = 0\n",
        "images_with_detections = 0\n",
        "\n",
        "# Suppress standard output to ignore detailed logs\n",
        "with open(os.devnull, 'w') as fnull:\n",
        "    with redirect_stdout(fnull):\n",
        "        # Loop through each image in the folder\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(('.png', '.jpg', '.jpeg')):  # Ensure file is an image\n",
        "                image_path = os.path.join(folder_path, filename)\n",
        "                total_images += 1\n",
        "\n",
        "                # Use the model to detect objects in the image, verbose=False to suppress logging\n",
        "                result_predict = model.predict(source=image_path, imgsz=(640), verbose=False)\n",
        "\n",
        "                # Check if there are any detections\n",
        "                if len(result_predict[0].boxes) > 0:  # Check if there are any bounding boxes\n",
        "                    images_with_detections += 1\n",
        "\n",
        "                    # Display the image with detections\n",
        "                    detected_img = result_predict[0].plot()  # Plot the detections on the image\n",
        "                    cv2_imshow(detected_img)  # Display the detected image in Colab\n",
        "\n",
        "# Calculate the percentage of images with detections\n",
        "if total_images > 0:\n",
        "    detection_percentage = (images_with_detections / total_images) * 100\n",
        "else:\n",
        "    detection_percentage = 0\n",
        "\n",
        "# Print the overall report\n",
        "print(f\"Total images processed: {total_images}\")\n",
        "print(f\"Images with detections: {images_with_detections}\")\n",
        "print(f\"Percentage of images with detections: {detection_percentage:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obn6KChvuMnJ"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!wget http://14.225.204.171:9998/validate_data_2.zip\n",
        "!unzip /content/validate_data_2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "f9sb6f0hQ-0W",
        "outputId": "c2b2a7da-85e8-4ab5-b4a5-5f0683f21345"
      },
      "outputs": [],
      "source": [
        "Image_dir = '/content/validate/images'\n",
        "\n",
        "num_samples = 9\n",
        "image_files = os.listdir(Image_dir)\n",
        "\n",
        "# Randomly select num_samples images\n",
        "rand_images = random.sample(image_files, num_samples)\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(11, 11))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    image = rand_images[i]\n",
        "    ax = axes[i // 3, i % 3]\n",
        "    ax.imshow(plt.imread(os.path.join(Image_dir, image)))\n",
        "    ax.set_title(f'Image {i+1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VOE7gaaGF5e9",
        "outputId": "eb44b55a-35cd-423d-a408-c1be9c5c7ff9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from contextlib import redirect_stdout\n",
        "import logging\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Define paths\n",
        "model_path = '/content/best.pt'  # Path to your trained model\n",
        "input_folder = '/content/validate/images'           # Path to the folder containing images\n",
        "label_folder = '/content/validate/labels'           # Path to the folder containing ground truth labels\n",
        "output_folder = '/content/output'          # Path to save the output images\n",
        "csv_output_path = '/content/result/1st_model_evaluation_results.csv'  # Path to save the evaluation results CSV\n",
        "txt_output_path = '/content/result/1st_model_final_conclusion.txt'    # Path to save the final conclusion TXT\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Initialize lists to store evaluation results\n",
        "results_data = []\n",
        "image_with_detections_count = 0  # Counter for images with detections\n",
        "\n",
        "# Function to parse label file into a list of ground truth classes\n",
        "def parse_label_file(label_path):\n",
        "    classes = []\n",
        "    with open(label_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            class_id = parts[0]\n",
        "            # Map class IDs to class names if necessary\n",
        "            class_name = {\n",
        "                '5': '50kmh',\n",
        "                '6': '60kmh',\n",
        "                '7': '70kmh',\n",
        "                '8': '80kmh',\n",
        "                '9': '90kmh'\n",
        "            }.get(class_id, class_id)  # Default to class_id if not found\n",
        "            classes.append(class_name)\n",
        "    return classes\n",
        "\n",
        "# Suppress logging messages\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# Suppress detailed output from YOLO model predictions\n",
        "with open(os.devnull, 'w') as fnull:\n",
        "    with redirect_stdout(fnull):  # Suppress unwanted output\n",
        "        for image_name in os.listdir(input_folder):\n",
        "            # Full path to the image\n",
        "            image_path = os.path.join(input_folder, image_name)\n",
        "\n",
        "            # Check if the file is an image\n",
        "            if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                continue\n",
        "\n",
        "            # Perform detection\n",
        "            results = model.predict(source=image_path, verbose=False)\n",
        "\n",
        "            # Extract detected class names\n",
        "            detected_classes = [model.names[int(cls)] for cls in results[0].boxes.cls]\n",
        "\n",
        "            # If detections exist, increment the counter\n",
        "            if detected_classes:\n",
        "                image_with_detections_count += 1\n",
        "\n",
        "            # Corresponding label file\n",
        "            label_file = image_name.replace('.jpg', '.txt')  # Adjust extension if necessary\n",
        "            label_path = os.path.join(label_folder, label_file)\n",
        "\n",
        "            # Parse ground truth classes from label file\n",
        "            if os.path.exists(label_path):\n",
        "                gt_classes = parse_label_file(label_path)\n",
        "            else:\n",
        "                gt_classes = []\n",
        "\n",
        "            # Compare detections with ground truth classes\n",
        "            tp = len(set(detected_classes) & set(gt_classes))  # True Positives: correct class detections\n",
        "            fp = len(detected_classes) - tp  # False Positives: incorrect class detections\n",
        "            fn = len(gt_classes) - tp  # False Negatives: missed ground truth classes\n",
        "\n",
        "            # Save results\n",
        "            results_data.append({\n",
        "                'Image': image_name,\n",
        "                'True Positives': tp,\n",
        "                'False Positives': fp,\n",
        "                'False Negatives': fn,\n",
        "                'Detected Classes': detected_classes,\n",
        "                'Ground Truth Classes': gt_classes\n",
        "            })\n",
        "\n",
        "            # Save the output image with detections\n",
        "            detected_img = results[0].plot()\n",
        "            output_path = os.path.join(output_folder, f\"detected_{image_name}\")\n",
        "            cv2.imwrite(output_path, detected_img)\n",
        "            # Uncomment the line below if you want to display the image in Colab\n",
        "            cv2_imshow(detected_img)\n",
        "\n",
        "# Convert results to a DataFrame and save to CSV\n",
        "df = pd.DataFrame(results_data)\n",
        "df['Precision'] = df['True Positives'] / (df['True Positives'] + df['False Positives'])\n",
        "df['Recall'] = df['True Positives'] / (df['True Positives'] + df['False Negatives'])\n",
        "df['F1 Score'] = 2 * (df['Precision'] * df['Recall']) / (df['Precision'] + df['Recall'])\n",
        "\n",
        "# Save evaluation results to CSV\n",
        "df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "# Calculate overall evaluation metrics\n",
        "total_tp = df['True Positives'].sum()\n",
        "total_fp = df['False Positives'].sum()\n",
        "total_fn = df['False Negatives'].sum()\n",
        "\n",
        "overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "\n",
        "# Save final conclusion to TXT file\n",
        "with open(txt_output_path, 'w') as f:\n",
        "    f.write(f\"Overall Evaluation Metrics:\\n\")\n",
        "    f.write(f\"Total True Positives: {total_tp}\\n\")\n",
        "    f.write(f\"Total False Positives: {total_fp}\\n\")\n",
        "    f.write(f\"Total False Negatives: {total_fn}\\n\")\n",
        "    f.write(f\"Overall Precision: {overall_precision:.2f}\\n\")\n",
        "    f.write(f\"Overall Recall: {overall_recall:.2f}\\n\")\n",
        "    f.write(f\"Overall F1 Score: {overall_f1:.2f}\\n\")\n",
        "\n",
        "print(\"Evaluation completed and results saved to:\", csv_output_path)\n",
        "print(\"Final conclusion saved to:\", txt_output_path)\n",
        "\n",
        "# Print the number of images with detections\n",
        "print(f\"Total number of images with detections: {image_with_detections_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrFEQpacPsXu",
        "outputId": "0da70ce1-6e15-4574-f832-c455549dc87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation completed and results saved to: /content/result/1st_model_evaluation_results.csv\n",
            "Final conclusion saved to: /content/result/1st_model_final_conclusion.txt\n",
            "Total number of images with detections: 393\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from contextlib import redirect_stdout\n",
        "import logging\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Define paths\n",
        "model_path = '/content/best.pt'  # Path to your trained model\n",
        "input_folder = '/content/validate/images'           # Path to the folder containing images\n",
        "label_folder = '/content/validate/labels'           # Path to the folder containing ground truth labels\n",
        "output_folder = '/content/output'          # Path to save the output images\n",
        "csv_output_path = '/content/result/1st_model_evaluation_results.csv'  # Path to save the evaluation results CSV\n",
        "txt_output_path = '/content/result/1st_model_final_conclusion.txt'    # Path to save the final conclusion TXT\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Initialize lists to store evaluation results\n",
        "results_data = []\n",
        "image_with_detections_count = 0  # Counter for images with detections\n",
        "\n",
        "# Function to parse label file into a list of ground truth classes\n",
        "def parse_label_file(label_path):\n",
        "    classes = []\n",
        "    with open(label_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            class_id = parts[0]\n",
        "            # Map class IDs to class names if necessary\n",
        "            class_name = {\n",
        "                '5': '50kmh',\n",
        "                '6': '60kmh',\n",
        "                '7': '70kmh',\n",
        "                '8': '80kmh',\n",
        "                '9': '90kmh'\n",
        "            }.get(class_id, class_id)  # Default to class_id if not found\n",
        "            classes.append(class_name)\n",
        "    return classes\n",
        "\n",
        "# Suppress logging messages\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# Suppress detailed output from YOLO model predictions\n",
        "with open(os.devnull, 'w') as fnull:\n",
        "    with redirect_stdout(fnull):  # Suppress unwanted output\n",
        "        for image_name in os.listdir(input_folder):\n",
        "            # Full path to the image\n",
        "            image_path = os.path.join(input_folder, image_name)\n",
        "\n",
        "            # Check if the file is an image\n",
        "            if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                continue\n",
        "\n",
        "            # Perform detection\n",
        "            results = model.predict(source=image_path, verbose=False)\n",
        "\n",
        "            # Extract detected class names\n",
        "            detected_classes = [model.names[int(cls)] for cls in results[0].boxes.cls]\n",
        "\n",
        "            # If detections exist, increment the counter\n",
        "            if detected_classes:\n",
        "                image_with_detections_count += 1\n",
        "\n",
        "            # Corresponding label file\n",
        "            label_file = image_name.replace('.jpg', '.txt')  # Adjust extension if necessary\n",
        "            label_path = os.path.join(label_folder, label_file)\n",
        "\n",
        "            # Parse ground truth classes from label file\n",
        "            if os.path.exists(label_path):\n",
        "                gt_classes = parse_label_file(label_path)\n",
        "            else:\n",
        "                gt_classes = []\n",
        "\n",
        "            # Compare detections with ground truth classes\n",
        "            tp = len(set(detected_classes) & set(gt_classes))  # True Positives: correct class detections\n",
        "            fp = len(detected_classes) - tp  # False Positives: incorrect class detections\n",
        "            fn = len(gt_classes) - tp  # False Negatives: missed ground truth classes\n",
        "\n",
        "            # Save results\n",
        "            results_data.append({\n",
        "                'Image': image_name,\n",
        "                'True Positives': tp,\n",
        "                'False Positives': fp,\n",
        "                'False Negatives': fn,\n",
        "                'Detected Classes': detected_classes,\n",
        "                'Ground Truth Classes': gt_classes\n",
        "            })\n",
        "\n",
        "            # Save the output image with detections\n",
        "            detected_img = results[0].plot()\n",
        "            output_path = os.path.join(output_folder, f\"detected_{image_name}\")\n",
        "            cv2.imwrite(output_path, detected_img)\n",
        "            # Uncomment the line below if you want to display the image in Colab\n",
        "            #cv2_imshow(detected_img)\n",
        "\n",
        "# Convert results to a DataFrame and save to CSV\n",
        "df = pd.DataFrame(results_data)\n",
        "df['Precision'] = df['True Positives'] / (df['True Positives'] + df['False Positives'])\n",
        "df['Recall'] = df['True Positives'] / (df['True Positives'] + df['False Negatives'])\n",
        "df['F1 Score'] = 2 * (df['Precision'] * df['Recall']) / (df['Precision'] + df['Recall'])\n",
        "\n",
        "# Save evaluation results to CSV\n",
        "df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "# Calculate overall evaluation metrics\n",
        "total_tp = df['True Positives'].sum()\n",
        "total_fp = df['False Positives'].sum()\n",
        "total_fn = df['False Negatives'].sum()\n",
        "\n",
        "overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "\n",
        "# Save final conclusion to TXT file\n",
        "with open(txt_output_path, 'w') as f:\n",
        "    f.write(f\"Overall Evaluation Metrics:\\n\")\n",
        "    f.write(f\"Total True Positives: {total_tp}\\n\")\n",
        "    f.write(f\"Total False Positives: {total_fp}\\n\")\n",
        "    f.write(f\"Total False Negatives: {total_fn}\\n\")\n",
        "    f.write(f\"Overall Precision: {overall_precision:.2f}\\n\")\n",
        "    f.write(f\"Overall Recall: {overall_recall:.2f}\\n\")\n",
        "    f.write(f\"Overall F1 Score: {overall_f1:.2f}\\n\")\n",
        "\n",
        "print(\"Evaluation completed and results saved to:\", csv_output_path)\n",
        "print(\"Final conclusion saved to:\", txt_output_path)\n",
        "\n",
        "# Print the number of images with detections\n",
        "print(f\"Total number of images with detections: {image_with_detections_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FeyZ8mzF0lU"
      },
      "source": [
        "# Validate the team_mode with validate_image_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yotU6VRuGgQf",
        "outputId": "ba46b71e-ada1-4d8c-8943-2aa1fe2d81b5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from contextlib import redirect_stdout\n",
        "import logging\n",
        "\n",
        "# Define paths\n",
        "model_path = '/content/finish_best_0827.pt'  # Path to your trained model\n",
        "input_folder = '/content/validate/images'           # Path to the folder containing images\n",
        "label_folder = '/content/validate/labels'           # Path to the folder containing ground truth labels\n",
        "output_folder = '/content/output'          # Path to save the output images\n",
        "csv_output_path = '/content/result/team_model_evaluation_results.csv'  # Path to save the evaluation results CSV\n",
        "txt_output_path = '/content/result/final_conclusion.txt'    # Path to save the final conclusion TXT\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Initialize lists to store evaluation results\n",
        "results_data = []\n",
        "image_with_detections_count = 0  # Counter for images with detections\n",
        "\n",
        "# Function to parse label file into a list of ground truth classes\n",
        "def parse_label_file(label_path):\n",
        "    classes = []\n",
        "    with open(label_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            class_id = parts[0]\n",
        "            # Map class IDs to class names if necessary\n",
        "            class_name = {\n",
        "                '5': 'SpeedLimit_50',\n",
        "                '6': 'SpeedLimit_60',\n",
        "                '7': 'SpeedLimit_70',\n",
        "                '8': 'SpeedLimit_80',\n",
        "                '9': 'SpeedLimit_90'\n",
        "            }.get(class_id, class_id)  # Default to class_id if not found\n",
        "            classes.append(class_name)\n",
        "    return classes\n",
        "\n",
        "# Suppress logging messages\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# Suppress detailed output from YOLO model predictions\n",
        "with open(os.devnull, 'w') as fnull:\n",
        "    with redirect_stdout(fnull):  # Suppress unwanted output\n",
        "        for image_name in os.listdir(input_folder):\n",
        "            # Full path to the image\n",
        "            image_path = os.path.join(input_folder, image_name)\n",
        "\n",
        "            # Check if the file is an image\n",
        "            if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                continue\n",
        "\n",
        "            # Perform detection\n",
        "            results = model.predict(source=image_path, verbose=False)\n",
        "\n",
        "            # Extract detected class names\n",
        "            detected_classes = [model.names[int(cls)] for cls in results[0].boxes.cls]\n",
        "\n",
        "            # If detections exist, increment the counter\n",
        "            if detected_classes:\n",
        "                image_with_detections_count += 1\n",
        "\n",
        "            # Corresponding label file\n",
        "            label_file = image_name.replace('.jpg', '.txt')  # Adjust extension if necessary\n",
        "            label_path = os.path.join(label_folder, label_file)\n",
        "\n",
        "            # Parse ground truth classes from label file\n",
        "            if os.path.exists(label_path):\n",
        "                gt_classes = parse_label_file(label_path)\n",
        "            else:\n",
        "                gt_classes = []\n",
        "\n",
        "            # Compare detections with ground truth classes\n",
        "            tp = len(set(detected_classes) & set(gt_classes))  # True Positives: correct class detections\n",
        "            fp = len(detected_classes) - tp  # False Positives: incorrect class detections\n",
        "            fn = len(gt_classes) - tp  # False Negatives: missed ground truth classes\n",
        "\n",
        "            # Save results\n",
        "            results_data.append({\n",
        "                'Image': image_name,\n",
        "                'True Positives': tp,\n",
        "                'False Positives': fp,\n",
        "                'False Negatives': fn,\n",
        "                'Detected Classes': detected_classes,\n",
        "                'Ground Truth Classes': gt_classes\n",
        "            })\n",
        "\n",
        "            # Save the output image with detections\n",
        "            detected_img = results[0].plot()\n",
        "            output_path = os.path.join(output_folder, f\"detected_{image_name}\")\n",
        "            cv2.imwrite(output_path, detected_img)\n",
        "            # Uncomment the line below if you want to display the image in Colab\n",
        "            cv2_imshow(detected_img)\n",
        "\n",
        "# Convert results to a DataFrame and save to CSV\n",
        "df = pd.DataFrame(results_data)\n",
        "df['Precision'] = df['True Positives'] / (df['True Positives'] + df['False Positives'])\n",
        "df['Recall'] = df['True Positives'] / (df['True Positives'] + df['False Negatives'])\n",
        "df['F1 Score'] = 2 * (df['Precision'] * df['Recall']) / (df['Precision'] + df['Recall'])\n",
        "\n",
        "# Save evaluation results to CSV\n",
        "df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "# Calculate overall evaluation metrics\n",
        "total_tp = df['True Positives'].sum()\n",
        "total_fp = df['False Positives'].sum()\n",
        "total_fn = df['False Negatives'].sum()\n",
        "\n",
        "overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "\n",
        "# Save final conclusion to TXT file\n",
        "with open(txt_output_path, 'w') as f:\n",
        "    f.write(f\"Overall Evaluation Metrics:\\n\")\n",
        "    f.write(f\"Total True Positives: {total_tp}\\n\")\n",
        "    f.write(f\"Total False Positives: {total_fp}\\n\")\n",
        "    f.write(f\"Total False Negatives: {total_fn}\\n\")\n",
        "    f.write(f\"Overall Precision: {overall_precision:.2f}\\n\")\n",
        "    f.write(f\"Overall Recall: {overall_recall:.2f}\\n\")\n",
        "    f.write(f\"Overall F1 Score: {overall_f1:.2f}\\n\")\n",
        "\n",
        "print(\"Evaluation completed and results saved to:\", csv_output_path)\n",
        "print(\"Final conclusion saved to:\", txt_output_path)\n",
        "\n",
        "# Print the number of images with detections\n",
        "print(f\"Total number of images with detections: {image_with_detections_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "BOAf-PS-Wi1l",
        "outputId": "1c22d2ed-7999-48fd-b2b2-5fc8429bccab"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'YOLO' from 'ultralytics' (unknown location)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0e152faa69fa>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mredirect_stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'YOLO' from 'ultralytics' (unknown location)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from contextlib import redirect_stdout\n",
        "import logging\n",
        "\n",
        "# Define paths\n",
        "model_path = '/content/finish_best_0827.pt'  # Path to your trained model\n",
        "input_folder = '/content/validate/images'           # Path to the folder containing images\n",
        "label_folder = '/content/validate/labels'           # Path to the folder containing ground truth labels\n",
        "output_folder = '/content/output'          # Path to save the output images\n",
        "csv_output_path = '/content/result/team_model_evaluation_results.csv'  # Path to save the evaluation results CSV\n",
        "txt_output_path = '/content/result/final_conclusion.txt'    # Path to save the final conclusion TXT\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Initialize lists to store evaluation results\n",
        "results_data = []\n",
        "image_with_detections_count = 0  # Counter for images with detections\n",
        "\n",
        "# Function to parse label file into a list of ground truth classes\n",
        "def parse_label_file(label_path):\n",
        "    classes = []\n",
        "    with open(label_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            class_id = parts[0]\n",
        "            # Map class IDs to class names if necessary\n",
        "            class_name = {\n",
        "                '5': 'SpeedLimit_50',\n",
        "                '6': 'SpeedLimit_60',\n",
        "                '7': 'SpeedLimit_70',\n",
        "                '8': 'SpeedLimit_80',\n",
        "                '9': 'SpeedLimit_90'\n",
        "            }.get(class_id, class_id)  # Default to class_id if not found\n",
        "            classes.append(class_name)\n",
        "    return classes\n",
        "\n",
        "# Suppress logging messages\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# Suppress detailed output from YOLO model predictions\n",
        "with open(os.devnull, 'w') as fnull:\n",
        "    with redirect_stdout(fnull):  # Suppress unwanted output\n",
        "        for image_name in os.listdir(input_folder):\n",
        "            # Full path to the image\n",
        "            image_path = os.path.join(input_folder, image_name)\n",
        "\n",
        "            # Check if the file is an image\n",
        "            if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                continue\n",
        "\n",
        "            # Perform detection\n",
        "            results = model.predict(source=image_path, verbose=False)\n",
        "\n",
        "            # Extract detected class names\n",
        "            detected_classes = [model.names[int(cls)] for cls in results[0].boxes.cls]\n",
        "\n",
        "            # If detections exist, increment the counter\n",
        "            if detected_classes:\n",
        "                image_with_detections_count += 1\n",
        "\n",
        "            # Corresponding label file\n",
        "            label_file = image_name.replace('.jpg', '.txt')  # Adjust extension if necessary\n",
        "            label_path = os.path.join(label_folder, label_file)\n",
        "\n",
        "            # Parse ground truth classes from label file\n",
        "            if os.path.exists(label_path):\n",
        "                gt_classes = parse_label_file(label_path)\n",
        "            else:\n",
        "                gt_classes = []\n",
        "\n",
        "            # Compare detections with ground truth classes\n",
        "            tp = len(set(detected_classes) & set(gt_classes))  # True Positives: correct class detections\n",
        "            fp = len(detected_classes) - tp  # False Positives: incorrect class detections\n",
        "            fn = len(gt_classes) - tp  # False Negatives: missed ground truth classes\n",
        "\n",
        "            # Save results\n",
        "            results_data.append({\n",
        "                'Image': image_name,\n",
        "                'True Positives': tp,\n",
        "                'False Positives': fp,\n",
        "                'False Negatives': fn,\n",
        "                'Detected Classes': detected_classes,\n",
        "                'Ground Truth Classes': gt_classes\n",
        "            })\n",
        "\n",
        "            # Save the output image with detections\n",
        "            detected_img = results[0].plot()\n",
        "            output_path = os.path.join(output_folder, f\"detected_{image_name}\")\n",
        "            cv2.imwrite(output_path, detected_img)\n",
        "            # Uncomment the line below if you want to display the image in Colab\n",
        "            # cv2_imshow(detected_img)\n",
        "\n",
        "# Convert results to a DataFrame and save to CSV\n",
        "df = pd.DataFrame(results_data)\n",
        "df['Precision'] = df['True Positives'] / (df['True Positives'] + df['False Positives'])\n",
        "df['Recall'] = df['True Positives'] / (df['True Positives'] + df['False Negatives'])\n",
        "df['F1 Score'] = 2 * (df['Precision'] * df['Recall']) / (df['Precision'] + df['Recall'])\n",
        "\n",
        "# Save evaluation results to CSV\n",
        "df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "# Calculate overall evaluation metrics\n",
        "total_tp = df['True Positives'].sum()\n",
        "total_fp = df['False Positives'].sum()\n",
        "total_fn = df['False Negatives'].sum()\n",
        "\n",
        "overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "\n",
        "# Save final conclusion to TXT file\n",
        "with open(txt_output_path, 'w') as f:\n",
        "    f.write(f\"Overall Evaluation Metrics:\\n\")\n",
        "    f.write(f\"Total True Positives: {total_tp}\\n\")\n",
        "    f.write(f\"Total False Positives: {total_fp}\\n\")\n",
        "    f.write(f\"Total False Negatives: {total_fn}\\n\")\n",
        "    f.write(f\"Overall Precision: {overall_precision:.2f}\\n\")\n",
        "    f.write(f\"Overall Recall: {overall_recall:.2f}\\n\")\n",
        "    f.write(f\"Overall F1 Score: {overall_f1:.2f}\\n\")\n",
        "\n",
        "print(\"Evaluation completed and results saved to:\", csv_output_path)\n",
        "print(\"Final conclusion saved to:\", txt_output_path)\n",
        "\n",
        "# Print the number of images with detections\n",
        "print(f\"Total number of images with detections: {image_with_detections_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AVAwMEwZXU17"
      },
      "outputs": [],
      "source": [
        "rm -r /content/ultralytics"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
